# 初识Netty

## 什么是Netty
* Netty是一个提供了易于使用的API的客户端/服务器框架
* 并发高-NIO(非阻塞)
* 传输快-零拷贝

## 关于零拷贝
以往的正常读取数据的流程是
* (1)从IO流中读出来，放到缓存区中
* (2)再到缓存区中读，放到堆中

对于资源数据很大的情况下，会造成内存空间的浪费<br>
Netty使用了NIO中的零拷贝技术<br>
<strong>使用Netty接收传输数据，会直接开辟一块堆内存，将数据从IO直接读到堆内存中，加快数据传输的速度</strong>

## 阻塞与非阻塞
即线程访问资源，该资源是否准备就绪的一种处理方式
我们去访问某资源，若该资源尚未准备就绪，则此时会有两种处理方式：
* 阻塞：线程会一直等待资源处理完毕，直到他响应返回一个结果，中间线程是处于一个阻塞的状态，无法去做其他任何的事情
* 非阻塞:线程发送请求后，可以同时继续干其他的事情
(针对线程，会不会阻塞)

## 同步与异步
同步和异步是指访问数据的一种机制
同步是发送请求后，需要自己去轮询（每隔一段时间去看看水开了没）
异步是线程主动请求数据后，过一段时间,服务端通过某种方式主动通知我
(针对操作结果，会不会等待结果返回)

## BIO
BIO，即同步阻塞IO，Block IO<br>
BIO模式下，IO在进行读写的时候，线程会被阻塞，无法去做其他的操作,并积极等待服务端的响应<br>
使用简单，操作方便，但显然性能会非常低，线程间通信耗时也会非常久<br>
![无法加载图片](https://github.com/Ywfy/Learning-Netty/blob/master/Introduce/159.png)<br>
通信模型如上，服务端会有一个线程专门用来监听和客户端之间的请求,只要有客户端跟服务端建立请求，则客户端和服务端都会创建一个新的线程来进行通信处理。<br>
这是非常典型的“应答模式”，当客户端非常多的时候，客户端跟服务端之间会频繁地创建和销量线程，服务器会有很大的压力<br>
之后进行了改良，不再使用新增线程，而是采用线程池的方式，客户端就需要等待服务端有空闲的线程

## NIO
NIO，即同步非阻塞IO，New IO(Non-Block IO)<br>
NIO模式下，IO在进行读写的时候，线程不会被阻塞，可以一边去做其他的操作，并积极等待服务端的响应
![无法加载图片](https://github.com/Ywfy/Learning-Netty/blob/master/Introduce/123.png)<br>
通信模型如上，若客户端想要跟服务端建立通信，则先要在Selector注册，注册成功后会生成一个对应的Channel
Channel是一个双向通道，可以进行数据的读写，最终都是到buffer缓存区里面去,若Channel没有数据，则直接跳过,不会进行等待<br>
这种模式的好处就是服务端只需要一个线程Selector，就可以处理成千上万个客户端

## AIO
AIO，即异步非阻塞IO
AIO模式下，发送请求后，线程继续干其他的事情，服务端主动通知后，再继续

以上厕所为例：
* BIO：去上厕所，坑全满了，我就站着那傻等着，主动观察哪个坑有人出来了，就立马占坑
* NIO：去上厕所，坑全满了，于是我在外面玩手机，时不时主动看一下有人出来了没，有就进去占坑
* 异步阻塞：去上厕所，坑全满了，我站在那傻等着发呆，等有人好了通知我，然后占坑
* AIO：在上厕所，坑全满了，于是我在外面玩手机，等有人好了通知我，我再去占坑

## Reactor线程模型
* 单线程模型：所有的IO操作都由同一个NIO线程处理

![无法加载图片](https://github.com/Ywfy/Learning-Netty/blob/master/Introduce/dxc.png)<br>
采用AIO，小规模场景适用

* 多线程模型:由一组NIO线程处理IO操作

![无法加载图片](https://github.com/Ywfy/Learning-Netty/blob/master/Introduce/ddxc.png)<br>
一个Reactor线程进行客户端连接监听，接收到一个客户端的连接请求后，就丢给后面的Reactor线程池进行后续的IO操作

* 主从线程模型：一组线程池接受请求，一组线程池处理IO

![无法加载图片](https://github.com/Ywfy/Learning-Netty/blob/master/Introduce/zxc.png)<br>
主线程池：主要进行登录校验，权限认证啥的,确定没问题就注册到从线程池中
从线程池：主要进行真正的IO操作
